# This file was created by the command:
# steps/nnet3/xconfig_to_configs.py --xconfig-file MTL/exp/nnet3/multitask/configs/network.xconfig --config-dir MTL/exp/nnet3/multitask/configs/ --nnet-edits=rename-node old-name=output-0 new-name=output
#It contains the same content as ./xconfig but it was parsed and
#default config values were set.
# See also ./xconfig.expanded.2

input name=input dim=13
relu-renorm-layer name=tdnn1 dim=768 dropout-proportion=0.5 input=Append(input@-2,input@-1,input,input@1,input@2) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn2 dim=768 dropout-proportion=0.5 input=[-1] learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn3 dim=768 dropout-proportion=0.5 input=Append(-1,2) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn4 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn5 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn6 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn7 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn8 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn9 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn10 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnn11 dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=tdnnFINAL dim=768 dropout-proportion=0.5 input=Append(-3,3) learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
relu-renorm-layer name=prefinal-affine-task-0 dim=768 dropout-proportion=0.5 input=tdnnFINAL learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
output-layer name=output-0 bias-stddev=0.0 dim=152 include-log-softmax=True input=[-1] learning-rate-factor=1.0 max-change=1.5 ng-affine-options= objective-type=linear output-delay=0 param-stddev=0.0 presoftmax-scale-file=
relu-renorm-layer name=prefinal-affine-task-1 dim=768 dropout-proportion=0.5 input=tdnnFINAL learning-rate-factor=1.0 max-change=0.75 ng-affine-options= self-repair-scale=1e-05 target-rms=1.0
output-layer name=output-1 bias-stddev=0.0 dim=192 include-log-softmax=True input=[-1] learning-rate-factor=1.0 max-change=1.5 ng-affine-options= objective-type=linear output-delay=0 param-stddev=0.0 presoftmax-scale-file=
